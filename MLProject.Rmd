---
author: "Mandy Simpson"
date: "10/10/2019"
title: "MLProject"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Netflix is a streaming service, enabling millions of users worldwide to access a large catalogue of movies on demand. Users are able to rate movies that they have watched using a star system of one star (low) to five stars (high), and are presented with personalised recommendations for new movies to watch.

This project, building a "recommendation system" is part of the [HarvardX Professional Certificate in Data Science](https://www.edx.org/professional-certificate/harvardx-data-science) Capstone course. It looks at how those recommendations are made, and in particular whether machine learning techniques can be used to improve predictions of the rating that a individual user will give to a particular movie.

For this project a dataset of 10 million ratings (the [MovieLens 10M Dataset](https://grouplens.org/datasets/movielens/10m/)) is used to enable the necessary calcuations to be run on an average home computer. The dataset is split into training and validation subsets. The training subset is used to create a range of machine learning algorithms which are then tested on the validation subset. 

Success is measured by considering the difference between the ratings predicted by each algorithm, and the actual ratings contained in validation subset. Root Mean Squared Error (RMSE) is used as a single measure of this difference. RMSE takes the square of the error for each prediction, creates an average of these, and then takes the square root of that average. A lower RMSE indicates a more accurate model.

# Methods and Analysis

## Installing required packages and downloading the data

The code below for installing the required R packages and downloading the MovieLens 10M dataset was provided as part of the course materials.

```{r install_and_download, results = "hide", message = FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)
```

## Data cleaning

The download contains three files, movies.dat, ratings.dat and tags.dat. Only the first two have been used for this project.

The following code was also provided as part of the course materials. This extracts the movies and ratings data, provides appropriate column headings for each, assigns numeric or character classes as needed, and joins the two tables into a single dataframe called `movielens`.

```{r initial_data_extraction, results = "hide", message = FALSE}
ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                           title = as.character(title),
                                           genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")
```

## Creating training and validation sets

The movielens dataset is now split into training and validation subsets, with the validation set being approximately 10% of the total. The training set is named `edx` and the validation set is named `validation`. 

Following the initial split any rows which are included in the `validation` subset, but with users or movies which are not also found in the `edx` subset are removed. These are then placed back into `edx`. 

Finally all objects created by this download and cleaning process, but which are not required going forward, are removed.

This code was provided as part of the course materials.

```{r create_training_validation_subsets, results = "hide", message = FALSE, warning = FALSE}
# Validation set will be 10% of MovieLens data

set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set

validation <- temp %>% 
     semi_join(edx, by = "movieId") %>%
     semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set

removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

## Inspecting and exploring the datasets

Both the `edx` and `validation` datasets include the following columns:

Name      | Type          | Contains
----------|---------------|---------------------------------------------------------|
userId    | integer       | Unique identification number for each user              |
movieId   | numeric       | Unique identification number for each movie             |
rating    | numeric       | Star rating from 1(low) to 5(high)                      |
timestamp | integer       | Date / time in UNIX timestamp format                    |
title     | character     | Movie title including release date in brackets          |
genres    | character     | Movie genre(s) - multiple genres allowed for each movie |

The `edx` dataset has `r format(dim(edx)[1],big.mark = ",")` rows, each representing a single rating by one user of one movie.

Within the `edx` dataset there are `r format(n_distinct(edx$userId),big.mark = ",")` individual users and `r format(n_distinct(edx$movieId),big.mark = ",")` individual movies represented. This gives a potential total of `r format(n_distinct(edx$userId) * n_distinct(edx$movieId),big.mark = ",")` possible ratings. However, as seen above, only `r format(dim(edx)[1],big.mark = ",")` ratings are included, just `r round((dim(edx)[1] * 100) / (n_distinct(edx$userId) * n_distinct(edx$movieId)),2)`% of the possible total. 

If we represented this data as a table with users as rows and movies as columns, some cells would have ratings but the vast majority would be empty. The task of a recommendation system is, in essence, completing the blank cells.

Below is this table for a sample (at random) of 100 users and 100 movies from the `edx` training set:

```{r visualise_users_movies, echo = FALSE, warning = FALSE}
users <- sample(unique(edx$userId), 100)
edx %>% filter(userId %in% users) %>% 
      select(userId, movieId, rating) %>%
      mutate(rating = 1) %>%
      spread(movieId, rating) %>% select(sample(ncol(.), 100)) %>% 
      as.matrix() %>% t(.) %>%
      image(1:100, 1:100,. , xlab="Movies", ylab="Users")
abline(h=0:100+0.5, v=0:100+0.5, col = "grey")
```

To understand the data better I reviewed the distributions of the number of ratings by user and by movie. 

```{r ratings_by_user, warning = FALSE}
edx %>%
     dplyr::count(userId) %>% 
     ggplot(aes(n)) + 
     geom_histogram(bins = 30, color = "black") + 
     scale_x_log10() +
     ggtitle("Users")
```

```{r ratings_by_movie, warning = FALSE}
edx %>% 
     dplyr::count(movieId) %>% 
     ggplot(aes(n)) + 
     geom_histogram(bins = 30, color = "black") + 
     scale_x_log10() + 
     ggtitle("Movies")
```

There is a wide distribution for each, with some users rating a lot more movies than others, and some movies being rated much more frequently than others. 

## Analysis

As RMSE is used for measuring success of the predictive algorithms, I start by defining a function to measure RMSE. This takes as inputs the predicted ratings when applying the algorthm in question to the `validation` dataset, and the actual ratings included in that dataset.  

The function is defined as follows:

```{r RMSE_function, results="hide", warning=FALSE, message=FALSE}
RMSE <- function(true_ratings, predicted_ratings){
     sqrt(mean((true_ratings - predicted_ratings)^2))
}
```

### Average

A initial basis for measuring improvement is created by using a very basic algorithm in which every user and movie is given the same rating prediction - the average of all the ratings in the training set.

This is calculated as follows:
```{r base_algorithm, results="hide", warning=FALSE, message=FALSE}
average_rating <- mean(edx$rating)
```

The average turns out to be `r round(average_rating,2)` (rounded to 2d.p. for display only).

Applying the RMSE function
```{r RMSE_base_algorithm}
base_rmse <- RMSE(validation$rating, average_rating)
```
shows an RMSE of `base_rmse`.  An RMSE that is greater than 1, means that on average the prediction is more than one star different to the actual result.

### Movie Effects

Some movies are more popular than others. We allow for the impact of this by adding a term that allows for the difference between the movie's average rating and the overall average rating (which we calculated earlier). 

```{r movie_effects_algorithm}
movie_avgs <- edx %>% 
  group_by(movieId) %>% 
  summarize(b_i = mean(rating - average_rating))
```

The differences are large (given these are how far each average is from the overall average of `r round(average_rating,2)`).

```{r plot_distribution_movie_effects}
movie_avgs %>% qplot(b_i, geom ="histogram", bins = 10, data = ., color = I("black"))
```

The predicted ratings are calculated on the `validation` dataset using this improved algorithm, and compared to the actual ratings to get a new RMSE.

```{r calculate_movie_predictions_rmse}
movie_effects <- average_rating + validation %>% 
     left_join(movie_avgs, by='movieId') %>%
     .$b_i
movie_effects_rmse <- RMSE(movie_effects, validation$rating)
```

The RMSE of the algorithm with movie effects incorporated falls to `r movie_effects_rmse`


# Results

A initial basis for measuring improvement was created by using a very basic algorithm in which every user and movie is given the same rating prediction - the average of all the ratings in the training set. This gave a RMSE of xxxx. An RMSE that is greater than 1, means that on average the prediction is more than one star different to the actual result.


# Conclusion

